







<!DOCTYPE HTML>
<html lang="zh_CN">
<head>
  <meta charset="UTF-8">
  <title>雪球爬虫设计 - 记录-好好工作</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1">
  
  <title>雪球爬虫设计</title>
  <meta name="description" content="主要说明下整个爬虫代码的逻辑与处理流程。
功能分析 代码结构 按功能模块划分，
 vendors-外部库 modules-主要模块 tools-工具函数 main.py-主程序入口  主要逻辑  初步假设每个循环功能模块在独立的线程中。
 分为以下几个部分，
 交互console 轮询是否有新消息 请求timeline 解析html数据 保存爬取的数据 获取代理 获取账号 更新账号关注 远程指令，参数获取 日志输出  1.交互console 由DEAMON参数决定是否启动，如果不启动console程序将在后台运行。 主要完成命令的输入和运行状态的输出。
2.轮询是否有新消息 通过下面的接口GET请求，
http://xueqiu.com/remind/unread.json?_=1458614506219  返回的数据如下，
{&quot;status&quot;:0,&quot;followers&quot;:0,&quot;dm&quot;:0,&quot;comments&quot;:0,&quot;mentions&quot;:0,&quot;notices&quot;:0,&quot;events&quot;:0,&quot;contact_friends&quot;:0,&quot;weibo_friends&quot;:0,&quot;events_id&quot;:[],&quot;ptl_status&quot;:0,&quot;ptl_last_modified&quot;:0}  账号需要重新登录会返回如下数据，
{&quot;error_description&quot;:&quot;遇到错误，请刷新页面或者重新登录帐号后再试&quot;,&quot;error_uri&quot;:&quot;/remind/unread.json&quot;,&quot;error_code&quot;:&quot;400016&quot;}  所以可以在这里检测账号的状态。
其中status段就是未阅读的消息数目。
参数frequency接受1~1000的整数，是轮询的频率，单位是秒；理论上这个数值越高，账号越安全，不宜过大，防止一次爬取不及时和单次数据太多。 在雪球自己的web端这个参数大概是小于10s。
如果该部分的结果返回大于0，即有新的动态需要抓取。
 抓取步骤应该在这一步来完成，因为timeline请求是得到最新的消息，这两步应该是阻塞运行。
 3.请求timeline 如果frequency合适，一次请求能够完成需求。 请求成功，把数据丢给解析模块；请求失败，抛出错误信息。
4.解析html数据 读取队列的数据，进行解析操作，把解析完成的数据丢给存储模块。
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 可以把解析规则，用参数传入。
5.保存爬取的数据 读取队列数据，
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 6.获取代理 先拿到账号，再拿回一个可用代理，如果无代理返回，抛出无代理错误。 传入的参数为lastip，返回lastip；如果，而且allowlike为 0，则无论这个代理是否在使用都返回该ip；否则抛出。
判断逻辑， 如果allowmax参数为num，从代理库选出所有可用且已经代理了num-1个账号的代理，如果lastip在其中，则返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错； 如果allowmax参数为1，从代理库选出所有可用且未被占用代理，如果lastip在其中，而且返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错。">
  
  <meta name="author" content="">
  <meta name="keywords" content="">
  <link rel="icon" href="/favicon.png">
  
  
  <meta itemprop="name" content="雪球爬虫设计 - 记录-好好工作">
  <meta itemprop="description" content="主要说明下整个爬虫代码的逻辑与处理流程。
功能分析 代码结构 按功能模块划分，
 vendors-外部库 modules-主要模块 tools-工具函数 main.py-主程序入口  主要逻辑  初步假设每个循环功能模块在独立的线程中。
 分为以下几个部分，
 交互console 轮询是否有新消息 请求timeline 解析html数据 保存爬取的数据 获取代理 获取账号 更新账号关注 远程指令，参数获取 日志输出  1.交互console 由DEAMON参数决定是否启动，如果不启动console程序将在后台运行。 主要完成命令的输入和运行状态的输出。
2.轮询是否有新消息 通过下面的接口GET请求，
http://xueqiu.com/remind/unread.json?_=1458614506219  返回的数据如下，
{&quot;status&quot;:0,&quot;followers&quot;:0,&quot;dm&quot;:0,&quot;comments&quot;:0,&quot;mentions&quot;:0,&quot;notices&quot;:0,&quot;events&quot;:0,&quot;contact_friends&quot;:0,&quot;weibo_friends&quot;:0,&quot;events_id&quot;:[],&quot;ptl_status&quot;:0,&quot;ptl_last_modified&quot;:0}  账号需要重新登录会返回如下数据，
{&quot;error_description&quot;:&quot;遇到错误，请刷新页面或者重新登录帐号后再试&quot;,&quot;error_uri&quot;:&quot;/remind/unread.json&quot;,&quot;error_code&quot;:&quot;400016&quot;}  所以可以在这里检测账号的状态。
其中status段就是未阅读的消息数目。
参数frequency接受1~1000的整数，是轮询的频率，单位是秒；理论上这个数值越高，账号越安全，不宜过大，防止一次爬取不及时和单次数据太多。 在雪球自己的web端这个参数大概是小于10s。
如果该部分的结果返回大于0，即有新的动态需要抓取。
 抓取步骤应该在这一步来完成，因为timeline请求是得到最新的消息，这两步应该是阻塞运行。
 3.请求timeline 如果frequency合适，一次请求能够完成需求。 请求成功，把数据丢给解析模块；请求失败，抛出错误信息。
4.解析html数据 读取队列的数据，进行解析操作，把解析完成的数据丢给存储模块。
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 可以把解析规则，用参数传入。
5.保存爬取的数据 读取队列数据，
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 6.获取代理 先拿到账号，再拿回一个可用代理，如果无代理返回，抛出无代理错误。 传入的参数为lastip，返回lastip；如果，而且allowlike为 0，则无论这个代理是否在使用都返回该ip；否则抛出。
判断逻辑， 如果allowmax参数为num，从代理库选出所有可用且已经代理了num-1个账号的代理，如果lastip在其中，则返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错； 如果allowmax参数为1，从代理库选出所有可用且未被占用代理，如果lastip在其中，而且返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错。">
  <meta itemprop="image" content="img/author.jpg">
  
  
  <meta name="twitter:description" content="">
  
  <link rel="shortcut icon" href="img/favicon.ico"/>
  <link rel="apple-touch-icon" href="apple-touch-icon.png" />
  <link rel="apple-touch-icon-precomposed" href="apple-touch-icon.png" />

  
  <meta name="description" content="主要说明下整个爬虫代码的逻辑与处理流程。
功能分析 代码结构 按功能模块划分，
 vendors-外部库 modules-主要模块 tools-工具函数 main.py-主程序入口  主要逻辑  初步假设每个循环功能模块在独立的线程中。
 分为以下几个部分，
 交互console 轮询是否有新消息 请求timeline 解析html数据 保存爬取的数据 获取代理 获取账号 更新账号关注 远程指令，参数获取 日志输出  1.交互console 由DEAMON参数决定是否启动，如果不启动console程序将在后台运行。 主要完成命令的输入和运行状态的输出。
2.轮询是否有新消息 通过下面的接口GET请求，
http://xueqiu.com/remind/unread.json?_=1458614506219  返回的数据如下，
{&quot;status&quot;:0,&quot;followers&quot;:0,&quot;dm&quot;:0,&quot;comments&quot;:0,&quot;mentions&quot;:0,&quot;notices&quot;:0,&quot;events&quot;:0,&quot;contact_friends&quot;:0,&quot;weibo_friends&quot;:0,&quot;events_id&quot;:[],&quot;ptl_status&quot;:0,&quot;ptl_last_modified&quot;:0}  账号需要重新登录会返回如下数据，
{&quot;error_description&quot;:&quot;遇到错误，请刷新页面或者重新登录帐号后再试&quot;,&quot;error_uri&quot;:&quot;/remind/unread.json&quot;,&quot;error_code&quot;:&quot;400016&quot;}  所以可以在这里检测账号的状态。
其中status段就是未阅读的消息数目。
参数frequency接受1~1000的整数，是轮询的频率，单位是秒；理论上这个数值越高，账号越安全，不宜过大，防止一次爬取不及时和单次数据太多。 在雪球自己的web端这个参数大概是小于10s。
如果该部分的结果返回大于0，即有新的动态需要抓取。
 抓取步骤应该在这一步来完成，因为timeline请求是得到最新的消息，这两步应该是阻塞运行。
 3.请求timeline 如果frequency合适，一次请求能够完成需求。 请求成功，把数据丢给解析模块；请求失败，抛出错误信息。
4.解析html数据 读取队列的数据，进行解析操作，把解析完成的数据丢给存储模块。
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 可以把解析规则，用参数传入。
5.保存爬取的数据 读取队列数据，
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 6.获取代理 先拿到账号，再拿回一个可用代理，如果无代理返回，抛出无代理错误。 传入的参数为lastip，返回lastip；如果，而且allowlike为 0，则无论这个代理是否在使用都返回该ip；否则抛出。
判断逻辑， 如果allowmax参数为num，从代理库选出所有可用且已经代理了num-1个账号的代理，如果lastip在其中，则返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错； 如果allowmax参数为1，从代理库选出所有可用且未被占用代理，如果lastip在其中，而且返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错。">
  <meta property="og:description" content="主要说明下整个爬虫代码的逻辑与处理流程。
功能分析 代码结构 按功能模块划分，
 vendors-外部库 modules-主要模块 tools-工具函数 main.py-主程序入口  主要逻辑  初步假设每个循环功能模块在独立的线程中。
 分为以下几个部分，
 交互console 轮询是否有新消息 请求timeline 解析html数据 保存爬取的数据 获取代理 获取账号 更新账号关注 远程指令，参数获取 日志输出  1.交互console 由DEAMON参数决定是否启动，如果不启动console程序将在后台运行。 主要完成命令的输入和运行状态的输出。
2.轮询是否有新消息 通过下面的接口GET请求，
http://xueqiu.com/remind/unread.json?_=1458614506219  返回的数据如下，
{&quot;status&quot;:0,&quot;followers&quot;:0,&quot;dm&quot;:0,&quot;comments&quot;:0,&quot;mentions&quot;:0,&quot;notices&quot;:0,&quot;events&quot;:0,&quot;contact_friends&quot;:0,&quot;weibo_friends&quot;:0,&quot;events_id&quot;:[],&quot;ptl_status&quot;:0,&quot;ptl_last_modified&quot;:0}  账号需要重新登录会返回如下数据，
{&quot;error_description&quot;:&quot;遇到错误，请刷新页面或者重新登录帐号后再试&quot;,&quot;error_uri&quot;:&quot;/remind/unread.json&quot;,&quot;error_code&quot;:&quot;400016&quot;}  所以可以在这里检测账号的状态。
其中status段就是未阅读的消息数目。
参数frequency接受1~1000的整数，是轮询的频率，单位是秒；理论上这个数值越高，账号越安全，不宜过大，防止一次爬取不及时和单次数据太多。 在雪球自己的web端这个参数大概是小于10s。
如果该部分的结果返回大于0，即有新的动态需要抓取。
 抓取步骤应该在这一步来完成，因为timeline请求是得到最新的消息，这两步应该是阻塞运行。
 3.请求timeline 如果frequency合适，一次请求能够完成需求。 请求成功，把数据丢给解析模块；请求失败，抛出错误信息。
4.解析html数据 读取队列的数据，进行解析操作，把解析完成的数据丢给存储模块。
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 可以把解析规则，用参数传入。
5.保存爬取的数据 读取队列数据，
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 6.获取代理 先拿到账号，再拿回一个可用代理，如果无代理返回，抛出无代理错误。 传入的参数为lastip，返回lastip；如果，而且allowlike为 0，则无论这个代理是否在使用都返回该ip；否则抛出。
判断逻辑， 如果allowmax参数为num，从代理库选出所有可用且已经代理了num-1个账号的代理，如果lastip在其中，则返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错； 如果allowmax参数为1，从代理库选出所有可用且未被占用代理，如果lastip在其中，而且返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错。">
  <meta property="og:type" content="blog">
  <meta property="og:title" content="雪球爬虫设计">
  <meta property="og:url" content="/w/post/2016-3-23-arch-design-for-xueqiu-spider/">
  <meta property="og:site_name" content="记录-好好工作">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="记录-好好工作">
  <meta name="twitter:description" content="主要说明下整个爬虫代码的逻辑与处理流程。
功能分析 代码结构 按功能模块划分，
 vendors-外部库 modules-主要模块 tools-工具函数 main.py-主程序入口  主要逻辑  初步假设每个循环功能模块在独立的线程中。
 分为以下几个部分，
 交互console 轮询是否有新消息 请求timeline 解析html数据 保存爬取的数据 获取代理 获取账号 更新账号关注 远程指令，参数获取 日志输出  1.交互console 由DEAMON参数决定是否启动，如果不启动console程序将在后台运行。 主要完成命令的输入和运行状态的输出。
2.轮询是否有新消息 通过下面的接口GET请求，
http://xueqiu.com/remind/unread.json?_=1458614506219  返回的数据如下，
{&quot;status&quot;:0,&quot;followers&quot;:0,&quot;dm&quot;:0,&quot;comments&quot;:0,&quot;mentions&quot;:0,&quot;notices&quot;:0,&quot;events&quot;:0,&quot;contact_friends&quot;:0,&quot;weibo_friends&quot;:0,&quot;events_id&quot;:[],&quot;ptl_status&quot;:0,&quot;ptl_last_modified&quot;:0}  账号需要重新登录会返回如下数据，
{&quot;error_description&quot;:&quot;遇到错误，请刷新页面或者重新登录帐号后再试&quot;,&quot;error_uri&quot;:&quot;/remind/unread.json&quot;,&quot;error_code&quot;:&quot;400016&quot;}  所以可以在这里检测账号的状态。
其中status段就是未阅读的消息数目。
参数frequency接受1~1000的整数，是轮询的频率，单位是秒；理论上这个数值越高，账号越安全，不宜过大，防止一次爬取不及时和单次数据太多。 在雪球自己的web端这个参数大概是小于10s。
如果该部分的结果返回大于0，即有新的动态需要抓取。
 抓取步骤应该在这一步来完成，因为timeline请求是得到最新的消息，这两步应该是阻塞运行。
 3.请求timeline 如果frequency合适，一次请求能够完成需求。 请求成功，把数据丢给解析模块；请求失败，抛出错误信息。
4.解析html数据 读取队列的数据，进行解析操作，把解析完成的数据丢给存储模块。
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 可以把解析规则，用参数传入。
5.保存爬取的数据 读取队列数据，
 注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。 程序启动时从本地备份区，读取恢复。
 6.获取代理 先拿到账号，再拿回一个可用代理，如果无代理返回，抛出无代理错误。 传入的参数为lastip，返回lastip；如果，而且allowlike为 0，则无论这个代理是否在使用都返回该ip；否则抛出。
判断逻辑， 如果allowmax参数为num，从代理库选出所有可用且已经代理了num-1个账号的代理，如果lastip在其中，则返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错； 如果allowmax参数为1，从代理库选出所有可用且未被占用代理，如果lastip在其中，而且返回lastip；如果lastip不在其中且allowlike为0，抛出代理可用错误；如果lastip不在其中且allowlike为1，返回相近的ip，未找到则报错。">
  
  

  
  

  

  
  
  

  

  
  
    <link rel="stylesheet" href="https://zi.com/w/css/public.min.css">
  
  

  
  
  
  

  
    
  
</head>
<body>
    
        
    
    <div class="container">
        

<p>主要说明下整个爬虫代码的逻辑与处理流程。</p>

<h3 id="功能分析">功能分析</h3>

<h3 id="代码结构">代码结构</h3>

<p>按功能模块划分，</p>

<ul>
<li>vendors-外部库</li>
<li>modules-主要模块</li>
<li>tools-工具函数</li>
<li>main.py-主程序入口</li>
</ul>

<h3 id="主要逻辑">主要逻辑</h3>

<blockquote>
<p>初步假设每个循环功能模块在独立的线程中。</p>
</blockquote>

<p>分为以下几个部分，</p>

<ul>
<li>交互console</li>
<li>轮询是否有新消息</li>
<li>请求timeline</li>
<li>解析html数据</li>
<li>保存爬取的数据</li>
<li>获取代理</li>
<li>获取账号</li>
<li>更新账号关注</li>
<li>远程指令，参数获取</li>
<li>日志输出</li>
</ul>

<h4 id="1-交互console">1.交互console</h4>

<p>由<code>DEAMON</code>参数决定是否启动，如果不启动console程序将在后台运行。
主要完成命令的输入和运行状态的输出。</p>

<h4 id="2-轮询是否有新消息">2.轮询是否有新消息</h4>

<p>通过下面的接口GET请求，</p>

<pre><code>http://xueqiu.com/remind/unread.json?_=1458614506219
</code></pre>

<p>返回的数据如下，</p>

<pre><code>{&quot;status&quot;:0,&quot;followers&quot;:0,&quot;dm&quot;:0,&quot;comments&quot;:0,&quot;mentions&quot;:0,&quot;notices&quot;:0,&quot;events&quot;:0,&quot;contact_friends&quot;:0,&quot;weibo_friends&quot;:0,&quot;events_id&quot;:[],&quot;ptl_status&quot;:0,&quot;ptl_last_modified&quot;:0}
</code></pre>

<p>账号需要重新登录会返回如下数据，</p>

<pre><code>{&quot;error_description&quot;:&quot;遇到错误，请刷新页面或者重新登录帐号后再试&quot;,&quot;error_uri&quot;:&quot;/remind/unread.json&quot;,&quot;error_code&quot;:&quot;400016&quot;}
</code></pre>

<p>所以可以在这里检测账号的状态。</p>

<p>其中<code>status</code>段就是未阅读的消息数目。</p>

<p>参数<code>frequency</code>接受1~1000的整数，是轮询的频率，单位是秒；理论上这个数值越高，账号越安全，不宜过大，防止一次爬取不及时和单次数据太多。
在雪球自己的web端这个参数大概是小于10s。</p>

<p>如果该部分的结果返回大于0，即有新的动态需要抓取。</p>

<blockquote>
<p>抓取步骤应该在这一步来完成，因为timeline请求是得到最新的消息，这两步应该是阻塞运行。</p>
</blockquote>

<h4 id="3-请求timeline">3.请求timeline</h4>

<p>如果frequency合适，一次请求能够完成需求。
请求成功，把数据丢给解析模块；请求失败，抛出错误信息。</p>

<h4 id="4-解析html数据">4.解析html数据</h4>

<p>读取队列的数据，进行解析操作，把解析完成的数据丢给存储模块。</p>

<blockquote>
<p>注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。
程序启动时从本地备份区，读取恢复。</p>
</blockquote>

<p>可以把解析规则，用参数传入。</p>

<h4 id="5-保存爬取的数据">5.保存爬取的数据</h4>

<p>读取队列数据，</p>

<blockquote>
<p>注意，一定要在程序关闭前，把queue中的数据保存到磁盘上，防止程序意外关闭时queue的数据丢失。
程序启动时从本地备份区，读取恢复。</p>
</blockquote>

<h4 id="6-获取代理">6.获取代理</h4>

<p>先拿到账号，再拿回一个可用代理，如果无代理返回，抛出无代理错误。
传入的参数为<code>lastip</code>，返回<code>lastip</code>；如果，而且<code>allowlike</code>为
<code>0</code>，则无论这个代理是否在使用都返回该ip；否则抛出。</p>

<p>判断逻辑，
如果<code>allowmax</code>参数为<code>num</code>，从代理库选出所有可用且已经代理了<code>num-1</code>个账号的代理，如果<code>lastip</code>在其中，则返回<code>lastip</code>；如果<code>lastip</code>不在其中且<code>allowlike</code>为<code>0</code>，抛出代理可用错误；如果<code>lastip</code>不在其中且<code>allowlike</code>为<code>1</code>，返回相近的ip，未找到则报错；
如果<code>allowmax</code>参数为<code>1</code>，从代理库选出所有可用且未被占用代理，如果lastip在其中，而且返回<code>lastip</code>；如果<code>lastip</code>不在其中且<code>allowlike</code>为<code>0</code>，抛出代理可用错误；如果<code>lastip</code>不在其中且<code>allowlike</code>为<code>1</code>，返回相近的ip，未找到则报错。</p>

<h4 id="7-获取账号">7.获取账号</h4>

<p>拿取账号，检测账号可用性；根据账号的<code>lastip</code>字段来获取代理ip，</p>

<h4 id="8-更新账号关注">8.更新账号关注</h4>

<p>从关注表中返回未被关注的账号，以及已经失效的uid对应的账号。
生成关注请求。</p>

<h4 id="9-远程指令-参数获取">9.远程指令，参数获取</h4>

<p>WebSocket监视，接受指令回传。</p>

<h4 id="10-日志输出">10.日志输出</h4>

<p>接受参数<code>type</code>，默认为Logger引擎写入日志数据，默认的Logger为[console, 配置中的日志文件对象]。</p>

    </div>
</body>

  

</html>